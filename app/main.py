import streamlit as st
import pandas as pd
import plotly.express as px
from openai import OpenAI
import os
import re
import numpy as np
import textwrap
from dotenv import load_dotenv

# =============================================================================
# [ì„¤ì •] íŒŒì¼ëª… ë§¤í•‘
# =============================================================================
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

load_dotenv() # .env íŒŒì¼ ë¡œë“œ
api_key = os.getenv("OPENAI_API_KEY")

FILE_CONFIG = {
    "MAIN_DATA": os.path.join(BASE_DIR, "data", "ê´€ê´‘ì§€_í˜¼ì¡ë„_ì°ìµœì¢…ê²°ê³¼ë¬¼.csv"),
    "PRED_DATA": os.path.join(BASE_DIR, "data", "AI_ì˜ˆì¸¡_ê²°ê³¼.csv"),
    "IMG_RANK_DATA": os.path.join(BASE_DIR, "data", "ê´€ê´‘ì§€_ë³„_ìœ ì‚¬ë„_ìˆœìœ„_refined.csv"), 
    "IMG_MATRIX_DATA": os.path.join(BASE_DIR, "data", "ë¶€ì‚°_ê´€ê´‘ì§€_ìœ ì‚¬ë„_ìµœì¢…_ê²°ê³¼_refined.csv"), 
    "REVIEW_SIM_DATA": os.path.join(BASE_DIR, "data", "ìœ ì‚¬ë„.csv"),                  
    "SENTIMENT_DATA": os.path.join(BASE_DIR, "data", "ê´€ê´‘ì§€_ê°ìƒìœ ì‚¬ë„_ë¶„ì„(ìµœì¢…, TF-IDFì ìš©).csv"),                   
    "FEATURE_DATA": os.path.join(BASE_DIR, "data", "ê´€ê´‘ì§€ë³„_í‚¤ì›Œë“œ_ìœ ì‚¬ë„_ìˆœìœ„.csv"),
    "KEYWORD_NOUN": os.path.join(BASE_DIR, "data", "ê´€ê´‘ì§€ë³„_í‚¤ì›Œë“œ50_ì¶”ì¶œ(ì •ì œí›„).csv"),
    "KEYWORD_ADJ": os.path.join(BASE_DIR, "data", "ë¶€ì‚°_ê´€ê´‘ì§€ë³„_í˜•ìš©ì‚¬_ì¶”ì¶œê²°ê³¼.csv"),
    "CATEGORY_INFO": os.path.join(BASE_DIR, "data", "ë¶€ì‚°_ê´€ê´‘ì§€ëª….xlsx")
}

# ì´ë¦„ ë§¤í•‘
NAME_MAPPING = {
    'ê´‘ì•ˆë¦¬SUPZONE': 'ê´‘ì•ˆëŒ€êµsup',
    'ì˜¤ë¥™ë„': 'ì˜¤ë¥™ë„ìŠ¤ì¹´ì´ì›Œí¬',
    'ë‹¤ëŒ€í¬ë‚™ì¡°ë¶„ìˆ˜': 'ë‹¤ëŒ€í¬ê¿ˆì˜ë‚™ì¡°ë¶„ìˆ˜',
    'ìš©í˜¸ë§Œë¶€ë‘': 'ìš©í˜¸ë§Œìœ ëŒì„ ',
    'ì„ìˆ™ë„ìƒíƒœê³µì›': 'ì„ìˆ™ë„',
    'ì•ˆë°ë¥´ì„¼ë§ˆì„': 'ì•ˆë°ë¥´ì„¼ë™í™”ë§ˆì„',
    'ì„ë‹¹ë°•ë¬¼ê´€': 'ë™ì•„ëŒ€ì„ë‹¹ë°•ë¬¼ê´€',
    'ë¶€ì‚°ì‹œë¦½ë°•ë¬¼ê´€': 'ë¶€ì‚°ë°•ë¬¼ê´€'
}

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(layout="wide", page_title="SLA PROJECT", page_icon="âš«")

# -----------------------------------------------------------------------------
# 2. [ë””ìì¸] CSS ìŠ¤íƒ€ì¼ë§
# -----------------------------------------------------------------------------
st.markdown("""
    <style>
    @import url("https://cdn.jsdelivr.net/gh/orioncactus/pretendard@v1.3.9/dist/web/static/pretendard.min.css");
    .stApp { font-family: 'Pretendard', sans-serif !important; background-color: #FFFFFF; }
    [data-testid="stSidebar"] { background-color: #000000 !important; border-right: 1px solid #222 !important; }
    [data-testid="stSidebar"] [data-testid="stExpander"] summary { color: #FFFFFF !important; font-weight: 700 !important; }
    [data-testid="stSidebar"] button { color: #FFFFFF !important; text-align: left !important; }
    
    div.stButton > button[kind="primary"] {
        background-color: #0F172A !important; color: #FFFFFF !important;
        border-radius: 8px; font-weight: 800 !important; border: 1px solid #0F172A !important;
    }
    div.stButton > button[kind="secondary"] {
        background-color: #F8FAFC !important; color: #333 !important;
        border: 1px solid #E2E8F0 !important; border-radius: 6px;
    }
    .stTabs [data-baseweb="tab-list"] { gap: 0px; border-bottom: 2px solid #000000; margin-bottom: 30px; }
    .stTabs [data-baseweb="tab"] { height: 60px; flex: 1; background: transparent; border: none; color: #9CA3AF; font-weight: 700; font-size: 1.2rem; }
    .stTabs [aria-selected="true"] { color: #000000 !important; background: #FAFAFA !important; border-bottom: 5px solid #000000 !important; }
    
    .sim-card { background: #FFFFFF; border: 1px solid #E5E5E5; border-radius: 12px; padding: 24px; margin-bottom: 15px; box-shadow: 0 4px 6px rgba(0,0,0,0.03); }
    .rank-card-mini { background: #F9F9F9; border: 1px solid #EEE; border-radius: 8px; padding: 15px; min-width: 150px; text-align: center; }
    .sim-rank-badge { background: #000; color: #FFF; padding: 4px 10px; border-radius: 4px; font-size: 0.8rem; font-weight: 700; margin-right: 8px; }
    .congestion-badge { font-size: 0.75rem; font-weight: 700; padding: 4px 8px; border-radius: 4px; display: inline-block; }
    .cong-good { background: #E0F2FE; color: #0284C7; border: 1px solid #0284C7; } 
    .cong-norm { background: #DCFCE7; color: #16A34A; border: 1px solid #16A34A; } 
    .cong-bad { background: #FEE2E2; color: #DC2626; border: 1px solid #DC2626; } 
    .ai-insight-box { background: #F8FAFC; border: 1px solid #E2E8F0; border-left: 6px solid #0F172A; padding: 20px; margin: 20px 0 30px 0; color: #333; line-height: 1.7; }
    .ai-header { font-weight: 800; font-size: 1rem; margin-bottom: 10px; color: #0F172A !important; display: flex; align-items: center; gap: 8px; }
    .ai-box-full-height { background-color: #F8FAFC; border: 1px solid #E2E8F0; border-radius: 10px; padding: 25px; height: 100%; min-height: 350px; display: flex; flex-direction: column; justify-content: center; }
    .meta-tag { display: inline-block; font-size: 0.75rem; font-weight: 600; padding: 3px 8px; margin: 0 4px 4px 0; border-radius: 4px; }
    .tag-common { background: #F3F4F6; color: #4B5563; border: 1px solid #E5E7EB; } 
    .tag-unique-source { background: #FFFFFF; color: #000; border: 1px solid #000; } 
    .tag-unique-target { background: #000; color: #FFF; border: 1px solid #000; } 
    .keyword-grid { display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 15px; margin-top: 15px; padding-top: 15px; border-top: 1px dashed #E2E8F0; }
    .keyword-col-header { font-size: 0.7rem; font-weight: 800; color: #64748B; margin-bottom: 8px; text-transform: uppercase; }
    .keyword-box { background: #FAFAFA; border: 2px solid #E5E5E5; border-radius: 12px; padding: 25px; margin-bottom: 30px; }
    .keyword-header { font-size: 1rem; font-weight: 900; color: #000; margin-bottom: 15px; border-left: 5px solid #000; padding-left: 12px; }
    .block-container { padding-top: 2rem; }
    
    /* ìº¡ì…˜ ê°€ìš´ë° ì •ë ¬ í´ë˜ìŠ¤ */
    .center-caption { text-align: center; color: #666; font-size: 0.9rem; margin-top: -10px; margin-bottom: 20px; line-height: 1.4; }
    </style>
    """, unsafe_allow_html=True)

# -----------------------------------------------------------------------------
# 3. [ë°ì´í„° ë¡œë“œ]
# -----------------------------------------------------------------------------
@st.cache_data
def load_data_smart(file_key):
    # 1. FILE_CONFIGì—ì„œ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
    file_path = FILE_CONFIG.get(file_key)
    
    if not file_path:
        st.error(f"âŒ FILE_CONFIGì— '{file_key}' ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()

    # 2. CSV íŒŒì¼ ë¡œë“œ ì‹œë„
    if os.path.exists(file_path):
        try:
            return pd.read_csv(file_path, encoding='utf-8-sig')
        except Exception:
            try:
                return pd.read_csv(file_path, encoding='cp949')
            except Exception as e:
                st.warning(f"âš ï¸ CSV ë¡œë“œ ì‹¤íŒ¨ ({file_key}): {e}")

    # 3. CSVê°€ ì—†ê±°ë‚˜ ì‹¤íŒ¨ ì‹œ XLSX íŒŒì¼ ë¡œë“œ ì‹œë„
    # í™•ì¥ì êµì²´ ë° ê²½ë¡œ ì •ì œ
    xlsx_path = file_path.replace('.csv', '.xlsx').strip()
    
    if os.path.exists(xlsx_path):
        try:
            # ì—‘ì…€ ë¡œë“œë¥¼ ìœ„í•´ openpyxl ì—”ì§„ ì‚¬ìš© ê¶Œì¥
            return pd.read_excel(xlsx_path, engine='openpyxl')
        except Exception as e:
            st.warning(f"âš ï¸ XLSX ë¡œë“œ ì‹¤íŒ¨ ({file_key}): {e}")

    # 4. ëª¨ë“  ì‹œë„ê°€ ì‹¤íŒ¨í•  ê²½ìš° ë¹ˆ ë°ì´í„°í”„ë ˆì„ ë°˜í™˜
    # st.error(f"ğŸ“‚ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
    return pd.DataFrame()

@st.cache_data
def get_category_map():
    cat_df = load_data_smart(FILE_CONFIG["CATEGORY_INFO"])
    if cat_df.empty: return {}
    cat_df.columns = cat_df.columns.str.strip()
    if 'ê´€ê´‘ì§€ëª…' in cat_df.columns and 'ì¹´í…Œê³ ë¦¬' in cat_df.columns:
        cat_df['ê´€ê´‘ì§€ëª…'] = cat_df['ê´€ê´‘ì§€ëª…'].astype(str).str.strip().replace(NAME_MAPPING)
        cat_df['ì¹´í…Œê³ ë¦¬'] = cat_df['ì¹´í…Œê³ ë¦¬'].astype(str).str.strip()
        return dict(zip(cat_df['ê´€ê´‘ì§€ëª…'], cat_df['ì¹´í…Œê³ ë¦¬']))
    return {}

CATEGORY_MAP = get_category_map()

@st.cache_data
def get_scaled_data():
    df_vis = load_data_smart(FILE_CONFIG["IMG_MATRIX_DATA"])
    df_sen = load_data_smart(FILE_CONFIG["SENTIMENT_DATA"])
    df_fea = load_data_smart(FILE_CONFIG["FEATURE_DATA"])
    
    if not df_fea.empty:
        df_fea['ê¸°ì¤€_ê´€ê´‘ì§€'] = df_fea['ê¸°ì¤€_ê´€ê´‘ì§€'].astype(str).str.strip().replace(NAME_MAPPING)
        df_fea['ë¹„êµ_ëŒ€ìƒ'] = df_fea['ë¹„êµ_ëŒ€ìƒ'].astype(str).str.strip().replace(NAME_MAPPING)

    if not df_sen.empty:
        df_sen['ê¸°ì¤€_ê´€ê´‘ì§€'] = df_sen['ê¸°ì¤€_ê´€ê´‘ì§€'].astype(str).str.strip().replace(NAME_MAPPING)
        df_sen['ë¹„êµ_ëŒ€ìƒ'] = df_sen['ë¹„êµ_ëŒ€ìƒ'].astype(str).str.strip().replace(NAME_MAPPING)

    vis_long = pd.DataFrame()
    if not df_vis.empty:
        df_vis.columns = df_vis.columns.str.strip()
        if df_vis.columns[0] == 'ê´€ê´‘ì§€ëª…':
            df_vis['ê´€ê´‘ì§€ëª…'] = df_vis['ê´€ê´‘ì§€ëª…'].astype(str).str.strip().replace(NAME_MAPPING)
        
        vis_long = df_vis.set_index(df_vis.columns[0]).stack().reset_index()
        vis_long.columns = ['ê¸°ì¤€_ê´€ê´‘ì§€', 'ë¹„êµ_ëŒ€ìƒ', 'VIS_RAW']
        vis_long['ê¸°ì¤€_ê´€ê´‘ì§€'] = vis_long['ê¸°ì¤€_ê´€ê´‘ì§€'].astype(str).str.strip().replace(NAME_MAPPING)
        vis_long['ë¹„êµ_ëŒ€ìƒ'] = vis_long['ë¹„êµ_ëŒ€ìƒ'].astype(str).str.strip().replace(NAME_MAPPING)
        
        v_min, v_max = vis_long['VIS_RAW'].min(), vis_long['VIS_RAW'].max()
        vis_long['VIS_SCALED'] = (vis_long['VIS_RAW'] - v_min) / (v_max - v_min + 1e-9)

    if not df_sen.empty and 'SBERT_ìœ ì‚¬ë„(ê°€ì¤‘ì ìš©)' in df_sen.columns:
        s_min, s_max = df_sen['SBERT_ìœ ì‚¬ë„(ê°€ì¤‘ì ìš©)'].min(), df_sen['SBERT_ìœ ì‚¬ë„(ê°€ì¤‘ì ìš©)'].max()
        df_sen['SEN_SCALED'] = (df_sen['SBERT_ìœ ì‚¬ë„(ê°€ì¤‘ì ìš©)'] - s_min) / (s_max - s_min + 1e-9)
    
    if not df_fea.empty and 'ìµœì¢…_ìœ ì‚¬ë„' in df_fea.columns:
        f_min, f_max = df_fea['ìµœì¢…_ìœ ì‚¬ë„'].min(), df_fea['ìµœì¢…_ìœ ì‚¬ë„'].max()
        df_fea['FEA_SCALED'] = (df_fea['ìµœì¢…_ìœ ì‚¬ë„'] - f_min) / (f_max - f_min + 1e-9)

    return vis_long, df_sen, df_fea

@st.cache_data
def load_all_data():
    df_main = load_data_smart(FILE_CONFIG["MAIN_DATA"])
    if not df_main.empty:
        df_main['ë‚ ì§œ'] = pd.to_datetime(df_main['ë‚ ì§œ'], format='mixed', errors='coerce')
        df_main = df_main.dropna(subset=['ë‚ ì§œ'])
        if 'í–‰ì •ë™' in df_main.columns:
            df_main['í–‰ì •êµ¬'] = df_main['í–‰ì •ë™'].astype(str).apply(lambda x: x.split()[0] if len(x.split()) > 0 else "ë¯¸ë¶„ë¥˜")
        else: df_main['í–‰ì •êµ¬'] = "ì „ì²´"
        
        df_main['ê´€ê´‘ì§€ëª…'] = df_main['ê´€ê´‘ì§€ëª…'].astype(str).str.strip().replace(NAME_MAPPING)
        
        if 'ì‹œê°„ëŒ€' in df_main.columns:
             df_main['ì‹œê°„ëŒ€_int'] = df_main['ì‹œê°„ëŒ€'].astype(str).str.replace('ì‹œ', '').apply(pd.to_numeric, errors='coerce')

    df_pred = load_data_smart(FILE_CONFIG["PRED_DATA"])
    if not df_pred.empty:
        df_pred['ds'] = pd.to_datetime(df_pred['ds'])
        df_pred['ê´€ê´‘ì§€ëª…'] = df_pred['ê´€ê´‘ì§€ëª…'].astype(str).str.strip().replace(NAME_MAPPING)

    df_noun = load_data_smart(FILE_CONFIG["KEYWORD_NOUN"])
    df_adj = load_data_smart(FILE_CONFIG["KEYWORD_ADJ"])
    
    if not df_noun.empty and 'ê´€ê´‘ì§€ëª…' in df_noun.columns:
        df_noun['ê´€ê´‘ì§€ëª…'] = df_noun['ê´€ê´‘ì§€ëª…'].astype(str).str.strip().replace(NAME_MAPPING)
    if not df_adj.empty and 'ê´€ê´‘ì§€ëª…' in df_adj.columns:
        df_adj['ê´€ê´‘ì§€ëª…'] = df_adj['ê´€ê´‘ì§€ëª…'].astype(str).str.strip().replace(NAME_MAPPING)

    return df_main, df_pred, df_noun, df_adj

main_df, forecast_df, noun_df, adj_df = load_all_data()
df_vis_scaled, df_sen_scaled, df_fea_scaled = get_scaled_data()

@st.cache_data
def get_global_top1_avg():
    df_img = load_data_smart(FILE_CONFIG["IMG_RANK_DATA"])
    if df_img.empty: return 0.5
    scores = []
    for val in df_img['1ìˆœìœ„'].dropna():
        m = re.search(r'\(([\d.]+)\)', str(val))
        if m: scores.append(float(m.group(1)))
    return np.mean(scores) if scores else 0.5

GLOBAL_TOP1_AVG = get_global_top1_avg()

def get_spot_category(name):
    if name in CATEGORY_MAP: return CATEGORY_MAP[name]
    return 'ê¸°íƒ€'

def classify_density(val):
    if val >= 1.2: return "ë§¤ìš°í˜¼ì¡"
    elif val >= 0.7: return "í˜¼ì¡"
    elif val >= 0.3: return "ë³´í†µ"
    else: return "ì¾Œì "

def get_smart_active_mean(df, spot_name):
    spot_df = df[df['ê´€ê´‘ì§€ëª…'] == spot_name]
    if spot_df.empty: return 0, "ì•Œìˆ˜ì—†ìŒ"
    
    hourly_grp = spot_df.groupby('ì‹œê°„ëŒ€_int')['ì‹¤ì§ˆ_ã¡ë‹¹_ë°©ë¬¸ê°ìˆ˜'].mean()
    if hourly_grp.empty: return 0, "ì•Œìˆ˜ì—†ìŒ"
    
    total_mean = hourly_grp.mean()
    base_hours = list(range(9, 19)) 
    active_hours = set(base_hours)
    
    for h in hourly_grp.index:
        val = hourly_grp[h]
        if h not in base_hours and val > total_mean:
            active_hours.add(h)
        if h in base_hours and val < total_mean:
            if h in active_hours: active_hours.remove(h)
            
    valid_vals = [hourly_grp[h] for h in active_hours if h in hourly_grp.index]
    
    if not valid_vals:
        final_val = total_mean
    else:
        final_val = np.mean(valid_vals)
        
    return final_val, classify_density(final_val)

def get_active_time_stats(df, spot_name, year=None):
    if year: spot_df = df[(df['ê´€ê´‘ì§€ëª…'] == spot_name) & (df['ë‚ ì§œ'].dt.year == year)]
    else: spot_df = df[df['ê´€ê´‘ì§€ëª…'] == spot_name]
    return get_smart_active_mean(spot_df, spot_name)

def get_ranking_info(df, spot_name, year):
    y_df = df[df['ë‚ ì§œ'].dt.year == year]
    if y_df.empty: return "ì •ë³´ ì—†ìŒ"
    
    rank_list = []
    for s in y_df['ê´€ê´‘ì§€ëª…'].unique():
        val, _ = get_smart_active_mean(y_df, s)
        rank_list.append({'spot': s, 'val': val})
    
    rank_df = pd.DataFrame(rank_list).sort_values(by='val', ascending=False).reset_index(drop=True)
    
    if spot_name not in rank_df['spot'].values: return "ì •ë³´ ì—†ìŒ"
    
    my_rank = rank_df[rank_df['spot'] == spot_name].index[0] + 1
    total = len(rank_df)
    percent = (my_rank / total) * 100
    
    return f"ì „ì²´ {total}ê³³ ì¤‘ {my_rank}ìœ„ (ìƒìœ„ {percent:.1f}%)"

def get_spot_keywords(spot_name):
    nouns, adjs = [], []
    if not noun_df.empty:
        row = noun_df[noun_df['ê´€ê´‘ì§€ëª…'] == spot_name]
        if not row.empty: nouns = [k.strip() for k in str(row.iloc[0]['ì •ì œí‚¤ì›Œë“œ']).split(',') if k.strip()][:30]
    if not adj_df.empty:
        row = adj_df[adj_df['ê´€ê´‘ì§€ëª…'] == spot_name]
        if not row.empty: adjs = [k.strip() for k in str(row.iloc[0]['ì¶”ì¶œ_í˜•ìš©ì‚¬']).split(',') if k.strip()][:30]
    if not nouns and not df_sen_scaled.empty:
        row = df_sen_scaled[df_sen_scaled['ê¸°ì¤€_ê´€ê´‘ì§€'] == spot_name]
        if not row.empty:
            raw_k = str(row.iloc[0].get('ê¸°ì¤€ì§€_ê³ ìœ _í‚¤ì›Œë“œ', ''))
            if raw_k and raw_k != 'nan':
                all_k = [k.strip() for k in raw_k.split(',') if k.strip()]
                nouns = all_k[:len(all_k)//2]
                adjs = all_k[len(all_k)//2:]
    return nouns, adjs

# [í˜ë¥´ì†Œë‚˜ ì •ì˜]
AI_SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ ë‚ ì¹´ë¡­ê³  ê¹Šì´ ìˆëŠ” í†µì°°ë ¥ì„ ê°€ì§„ ìˆ˜ì„ ë°ì´í„° ë¶„ì„ê°€ì…ë‹ˆë‹¤.
'ë¶„ì„í•˜ê² ìŠµë‹ˆë‹¤', 'ê²°ê³¼ì…ë‹ˆë‹¤', 'ì•ˆë…•í•˜ì„¸ìš”' ê°™ì€ í˜•ì‹ì ì¸ ì„œë¡ ì„ ì¼ì ˆ ìƒëµí•˜ê³ , ì¦‰ì‹œ í•µì‹¬ ìˆ˜ì¹˜ì™€ ê·¸ ì´ë©´ì˜ ì˜ë¯¸ë¥¼ íŒŒê³ ë“œì‹­ì‹œì˜¤.
ë¬¸ì¥ì€ ëª…ë£Œí•˜ë˜ ë‚´ìš©ì€ ì‹¬ì¸µì ì´ì–´ì•¼ í•˜ë©°, ë¶„ëŸ‰ì€ ì¶©ë¶„íˆ ê¸¸ê³  ìì„¸í•˜ê²Œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
í†¤ì€ ì „ë¬¸ì ì´ê³  ëƒ‰ì² í•œ ì¡´ëŒ“ë§(~ì…ë‹ˆë‹¤/í•©ë‹ˆë‹¤)ì„ ìœ ì§€í•˜ì‹­ì‹œì˜¤.
"""

def generate_spot_info_ai(spot_name):
    if not api_key: return "API Key Missing"
    try:
        client = OpenAI(api_key=api_key)
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "system", "content": AI_SYSTEM_PROMPT}, 
                      {"role": "user", "content": f"'{spot_name}'ì˜ ìœ„ì¹˜, ì£¼ìš” íŠ¹ì§•, ì—­ì‚¬ì /ë¬¸í™”ì  ë°°ê²½ì„ ì‹¬ì¸µì ìœ¼ë¡œ ì„œìˆ í•˜ì‹­ì‹œì˜¤."}], 
            temperature=0.3
        )
        return response.choices[0].message.content
    except: return "ì •ë³´ ë¡œë“œ ì‹¤íŒ¨"

def generate_visual_rank1_analysis(spot_name, rank1_name, rank1_score, avg_score, rank1_congestion):
    if not api_key: return "API Key Missing"
    
    score_diff = rank1_score - avg_score
    score_eval = f"í‰ê· ({avg_score:.2f})ë³´ë‹¤ {score_diff:+.2f}ì  ë†’ìŒ" if score_diff > 0 else "í‰ê·  ì´í•˜"
    
    policy_guide = ""
    if rank1_congestion in ["í˜¼ì¡", "ë§¤ìš°í˜¼ì¡"]:
        policy_guide = "í•´ë‹¹ ëŒ€ì²´ì§€ ì—­ì‹œ í˜„ì¬ 'í¬í™” ìƒíƒœ'ì…ë‹ˆë‹¤. ì´ê³³ìœ¼ë¡œì˜ ìœ ì… ìœ ë„ëŠ” í’ì„  íš¨ê³¼ë¥¼ ì´ˆë˜í•˜ë¯€ë¡œ ì •ì±…ì ìœ¼ë¡œ 'ë¶€ì ì ˆ'í•©ë‹ˆë‹¤."
    else:
        policy_guide = "í•´ë‹¹ ëŒ€ì²´ì§€ëŠ” í˜„ì¬ 'ìˆ˜ìš© ì—¬ë ¥'ì´ ì¶©ë¶„í•©ë‹ˆë‹¤. ì´ê³³ìœ¼ë¡œì˜ ìœ ì… ìœ ë„ëŠ” ë¶„ì‚° ì •ì±…ìƒ 'íƒ€ë‹¹'í•©ë‹ˆë‹¤."

    user_msg = f"""
    [ë¶„ì„ ëŒ€ìƒ]: {spot_name}
    [ì‹œê°ì  ëŒ€ì²´ì§€ 1ìœ„]: {rank1_name}
    [ë°ì´í„°]: ìœ ì‚¬ë„ {rank1_score:.4f} ({score_eval}), í˜¼ì¡ë„ '{rank1_congestion}'
    
    [ì§€ì‹œì‚¬í•­]
    ë‹¹ì‹ ì€ ì—„ê²©í•œ ë°ì´í„° ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì¸ì‚¬ë§(ì•ˆë…•í•˜ì„¸ìš” ë“±)ì„ ìƒëµí•˜ê³  ë°”ë¡œ ë¶„ì„ ë‚´ìš©ì„ ì„œìˆ í•˜ì‹­ì‹œì˜¤. ì •ì¤‘í•œ ì¡´ëŒ“ë§(~ì…ë‹ˆë‹¤/í•©ë‹ˆë‹¤)ì„ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤.
    
    1. **ëŒ€ì²´ì§€ ê¸°ë³¸ ì •ë³´**: {rank1_name}ì´ ì–´ë–¤ ê³³ì¸ì§€ ê°„ëµíˆ ì„¤ëª…í•˜ì‹­ì‹œì˜¤.
    2. **ìœ ì‚¬ë„ í‰ê°€**: ì „ì²´ í‰ê·  ëŒ€ë¹„ ìœ ì‚¬ë„ ìˆ˜ì¤€ì„ ìˆ˜ì¹˜ì™€ í•¨ê»˜ ê°ê´€ì ìœ¼ë¡œ ì„œìˆ í•˜ì‹­ì‹œì˜¤.
    3. **ìˆ˜ìš©ë ¥ ì§„ë‹¨**: ëŒ€ì²´ì§€ì˜ í˜„ì¬ í˜¼ì¡ë„ë¥¼ ê·¼ê±°ë¡œ, ë¶„ì‚° ìˆ˜ìš© ê°€ëŠ¥ ì—¬ë¶€ë¥¼ ëƒ‰ì •í•˜ê²Œ íŒì •í•˜ì‹­ì‹œì˜¤.
    
    (ì°¸ê³  ê°€ì´ë“œ: {policy_guide})
    """
    try:
        client = OpenAI(api_key=api_key)
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "system", "content": AI_SYSTEM_PROMPT}, {"role": "user", "content": user_msg}],
            temperature=0.3
        )
        return response.choices[0].message.content
    except Exception as e: return str(e)

def generate_strategic_analysis(source, candidates_data, anal_type="text"):
    if not api_key: return "âš ï¸ API Key Missing"
    candidates_text = ""
    for c in candidates_data:
        candidates_text += f"- {c['name']} (Rank {c['rank']}): ìœ ì‚¬ë„ {c['score']:.4f}, í˜¼ì¡ë„ [{c['congestion']}]\n"
    
    user_msg = f"""
    [ë¶„ì„ ëŒ€ìƒ]: {source.get('name', 'Unknown')} (í˜„ì¬ í˜¼ì¡ë„: {source.get('congestion', 'Unknown')})
    [ë¶„ì„ ìœ í˜•]: {anal_type} ê¸°ë°˜ ìœ ì‚¬ë„ í›„ë³´êµ°
    {candidates_text}
    
    [ì¶”ê°€ ì •ë³´]
    {source}

    [ìš”ì²­ì‚¬í•­]
    ë°ì´í„° ë¶„ì„ê°€ ì…ì¥ì—ì„œ ì§„ë‹¨í•˜ì‹­ì‹œì˜¤. ì¸ì‚¬ë§ì„ ì ˆëŒ€ í•˜ì§€ ë§ˆì‹­ì‹œì˜¤. ë°˜ë“œì‹œ ì¡´ëŒ“ë§(~ì…ë‹ˆë‹¤/í•©ë‹ˆë‹¤)ì„ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤.
    
    1. ìœ ì‚¬ë„ê°€ ë†’ìœ¼ë©´ì„œ í˜¼ì¡ë„ê°€ 'ì¾Œì /ë³´í†µ'ì¸ ê³³ì„ **'ìœ íš¨ ëŒ€ì²´ì§€'**ë¡œ ë¶„ë¥˜í•˜ì‹­ì‹œì˜¤.
    2. ìœ ì‚¬ë„ê°€ ë†’ë”ë¼ë„ í˜¼ì¡ë„ê°€ 'í˜¼ì¡/ë§¤ìš°í˜¼ì¡'ì¸ ê³³ì€ **'ëŒ€ì²´ ë¶ˆê°€(í¬í™”)'**ë¡œ ëª…ì‹œí•˜ì‹­ì‹œì˜¤.
    3. ì˜¤ì§ ë°ì´í„°ì— ê·¼ê±°í•˜ì—¬ ë¶„ì‚° ê°€ëŠ¥ì„± ì—¬ë¶€ë§Œ ê°ê´€ì ìœ¼ë¡œ ì„œìˆ í•˜ì‹­ì‹œì˜¤. (ì¶”ìƒì  ì „ëµ ì œì•ˆ ê¸ˆì§€)
    """
    try:
        client = OpenAI(api_key=api_key)
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "system", "content": AI_SYSTEM_PROMPT}, {"role": "user", "content": user_msg}],
            temperature=0.3
        )
        return response.choices[0].message.content
    except Exception as e: return f"Error: {str(e)}"

def generate_weighted_insight(spot_name, top_cand, weights):
    if not api_key: return "API Key Missing"
    user_msg = f"""
    [User Preferences - Weighted Priority]
    - Visual: {weights[0]}
    - Sentiment: {weights[1]}
    - Feature: {weights[2]}
    
    [Result]
    - Source: {spot_name}
    - Recommended: {top_cand['name']}
    - Scores: V({top_cand['raw_v']:.2f}), S({top_cand['raw_s']:.2f}), F({top_cand['raw_f']:.2f})
    
    [Task]
    Explain clearly and deeply why this spot was selected based on data scores. 
    No greetings. Start immediately.
    Use polite Korean (Honorifics).
    Max 5 sentences.
    """
    try:
        client = OpenAI(api_key=api_key)
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "system", "content": AI_SYSTEM_PROMPT}, {"role": "user", "content": user_msg}],
            temperature=0.3
        )
        return response.choices[0].message.content
    except Exception as e: return f"Error: {str(e)}"

def generate_section_analysis(section_type, spot_name, year, data_summary, congestion_stage, ranking_info="ì •ë³´ ì—†ìŒ"):
    if  not api_key: return "âš ï¸ API Key Missing"
    
    tone_guide = ""
    if congestion_stage in ["ì¾Œì ", "ë³´í†µ"]:
        tone_guide = """
        [Diagnosis]: ìˆ˜ìš© ì—¬ë ¥ ì¶©ë¶„ (Under Capacity).
        [Implication]: ë°ì´í„°ìƒ ê´€ê´‘ê° ì¶”ê°€ ìœ ì…ì´ ê°€ëŠ¥í•˜ë©°, ë¶„ì‚° ì •ì±…ì˜ ìˆ˜ìš©ì§€(Destination)ë¡œì„œ ì í•©í•¨.
        """
    else: # í˜¼ì¡, ë§¤ìš°í˜¼ì¡
        tone_guide = """
        [Diagnosis]: ìˆ˜ìš© í•œê³„ ì´ˆê³¼ (Over Capacity).
        [Implication]: ë°ì´í„°ìƒ ì¶”ê°€ ìœ ì… ì‹œ í˜¼ì¡ë„ ì„ê³„ì¹˜ë¥¼ ë„˜ìŒ. ë¶„ì‚° ì •ì±…ì˜ ëŒ€ìƒì§€(Source)ë¡œ ë¶„ë¥˜ë˜ì–´ì•¼ í•¨.
        """

    msg = f"""
    [Target]: {spot_name} ({year})
    [Type]: {section_type} Analysis
    [Status]: {congestion_stage}
    [Ranking]: {ranking_info}
    [Data]: {data_summary}
    
    [Instruction]
    You are a strict Data Analyst evaluating urban data.
    Do NOT use greetings (Hello, etc). Start analysis directly.
    Do NOT propose marketing strategies or vague improvements.
    Use polite Korean (Honorifics, ~ì…ë‹ˆë‹¤/í•©ë‹ˆë‹¤).
    
    {tone_guide}
    
    1. **Quantify**: Use the ranking info (Top X%) to define the spot's relative density clearly.
    2. **Analyze**: Interpret the volatility (standard deviation/peaks) and seasonality patterns in depth.
    3. **Conclude**: Diagnose the 'Capacity' status strictly based on data.
    """
    
    try:
        client = OpenAI(api_key=api_key)
        response = client.chat.completions.create(model="gpt-4o-mini", 
            messages=[{"role": "system", "content": AI_SYSTEM_PROMPT}, {"role": "user", "content": msg}], 
            temperature=0.3) 
        return response.choices[0].message.content, "#0F172A"
    except Exception as e: return str(e), "#000"

def get_ranking_dict(df, spot_name, year):
    y_df = df[df['ë‚ ì§œ'].dt.year == year]
    if y_df.empty: return None
    rank_list = [{'spot': spot, 'val': get_smart_active_mean(y_df, spot)[0]} for spot in y_df['ê´€ê´‘ì§€ëª…'].unique()]
    rank_df = pd.DataFrame(rank_list).sort_values(by='val', ascending=False).reset_index(drop=True)
    try:
        rank = rank_df[rank_df['spot'] == spot_name].index[0] + 1
        return {"rank": rank, "total": len(rank_df), "top_percent": (rank/len(rank_df))*100}
    except: return None

def style_chart(fig):
    fig.update_layout(
        paper_bgcolor="rgba(0,0,0,0)",
        plot_bgcolor="rgba(0,0,0,0)",
        font=dict(color="#111", family="Pretendard"),
        margin=dict(l=0, r=0, t=20, b=20),
        hovermode="x unified",
        xaxis=dict(showgrid=False, showline=True, linecolor="#000", linewidth=1),
        yaxis=dict(showgrid=True, gridcolor="#EEE", zeroline=False),
    )
    return fig

# -----------------------------------------------------------------------------
# 5. UI ë° ì„¸ì…˜
# -----------------------------------------------------------------------------
if 'selected_spot' not in st.session_state: st.session_state['selected_spot'] = None
if 'sel_year' not in st.session_state: st.session_state['sel_year'] = 2024
if 'sel_month' not in st.session_state: st.session_state['sel_month'] = 1
if 'sim_sub_tab' not in st.session_state: st.session_state['sim_sub_tab'] = "ì´ë¯¸ì§€ ìœ ì‚¬ë„"
if 'weighted_result' not in st.session_state: st.session_state['weighted_result'] = None
if 'cross_result' not in st.session_state: st.session_state['cross_result'] = None 
if 'analysis_results' not in st.session_state: 
    st.session_state['analysis_results'] = {'trend': {}, 'hourly': {}, 'forecast': {}, 'sim_strat': {}, 'sim_img': {}, 'spot_info': {}, 'visual_rank1': {}, 'weighted': {}}

with st.sidebar:
    st.markdown('<h3 style="color:white; margin-bottom:30px; font-weight:900; letter-spacing:1px; padding-left:10px;">SLA PROJECT</h3>', unsafe_allow_html=True)
    if not main_df.empty:
        gu_list = sorted(main_df['í–‰ì •êµ¬'].unique())
        for gu in gu_list:
            with st.expander(gu, expanded=False):
                spots = sorted(main_df[main_df['í–‰ì •êµ¬'] == gu]['ê´€ê´‘ì§€ëª…'].unique())
                for spot in spots:
                    btn_kind = "primary" if st.session_state['selected_spot'] == spot else "secondary"
                    # [ìˆ˜ì •] íƒ­ ì´ˆê¸°í™” ë¡œì§
                    if st.button(spot, key=f"btn_{gu}_{spot}", type=btn_kind):
                        st.session_state['selected_spot'] = spot
                        st.session_state['sel_month'] = 1 
                        st.session_state['sim_sub_tab'] = "ì´ë¯¸ì§€ ìœ ì‚¬ë„" 
                        st.session_state['weighted_result'] = None 
                        st.session_state['cross_result'] = None 
                        st.rerun()
    else: st.error("Data Load Failed")

if not st.session_state['selected_spot']:
    # [ìˆ˜ì •] ë©”ì¸ í™”ë©´ ë ˆì´ì•„ì›ƒ (ì¢Œ: í…ìŠ¤íŠ¸ / ìš°: ì´ë¯¸ì§€)
    col_text, col_img = st.columns([1, 1.3], gap="large", vertical_alignment="center")
    with col_text:
        st.markdown("""
        <div style="text-align: left; margin-left: 0px;">
            <div style="font-family:'Pretendard'; font-size:100px; font-weight:900; line-height:0.85; letter-spacing:-4px; color:#000;">SLA</div>
            <div style="font-family:'Pretendard'; font-size:100px; font-weight:900; line-height:0.85; letter-spacing:-4px; color:#000;">PROJECT</div>
            <div style="font-family:'Pretendard'; font-size:18px; font-weight:400; color:#666; margin-top:30px; letter-spacing:12px; margin-left:8px;">SPOT - LINEAR - AREA</div>
            <div style="margin-top:50px; border-left:4px solid black; padding-left:20px; color:#444;">
                <b>Sustainable Location Analysis</b><br>
                Solving Overtourism through Spatial Strategy.<br>
                "Connect the Dots, Create the Flow."
            </div>
        </div>""", unsafe_allow_html=True) 
    with col_img:
        st.markdown("""
        <div style="display:flex; justify-content: flex-end; align-items:center;">
            <img src="https://images.unsplash.com/photo-1558591710-4b4a1ae0f04d?q=80&w=1000&auto=format&fit=crop" 
                 style="width:90%; max-width:550px; filter:grayscale(100%) contrast(1.2); border:1px solid #E5E5E5; box-shadow: 0 10px 25px rgba(0,0,0,0.1);">
        </div>""", unsafe_allow_html=True)

else:
    spot_name = st.session_state["selected_spot"]
    st.title(spot_name)
    st.markdown(" ") 

    if spot_name not in st.session_state['analysis_results']['spot_info']:
        st.session_state['analysis_results']['spot_info'][spot_name] = generate_spot_info_ai(spot_name)
    
    with st.expander(f"â„¹ï¸ ABOUT {spot_name}", expanded=True):
        ic1, ic2 = st.columns([1, 2])
        with ic1:
            img_path = os.path.join(BASE_DIR,"images", f"{spot_name}.jpg")
            if os.path.exists(img_path): 
                st.image(img_path, use_container_width=True) 
            else: st.markdown("<div style='background:#F4F4F5; height:200px; display:flex; justify-content:center; align-items:center; color:#999;'>NO IMAGE</div>", unsafe_allow_html=True)
        with ic2:
            st.markdown(f"<div style='line-height:1.6; color:#333;'>{st.session_state['analysis_results']['spot_info'][spot_name]}</div>", unsafe_allow_html=True)

    # [ìˆ˜ì •] íƒ­ í‚¤ ì œê±°
    tab1, tab2 = st.tabs(["âš« CROWD ANALYSIS (í˜¼ì¡ë„)", "âšª SIMILARITY & DISPERSION (ìœ ì‚¬ë„)"])

    # TAB 1: í˜¼ì¡ë„
    with tab1:
        spot_data = main_df[main_df['ê´€ê´‘ì§€ëª…'] == spot_name].copy()
        # [ìˆ˜ì •] ì—°ë„ë³„ í•„í„° ì ìš©ëœ ë°°ì§€ ê³„ì‚°
        _, current_stage = get_active_time_stats(main_df, spot_name, st.session_state['sel_year'])
        st.markdown("<h3 style='font-size:1.5rem; font-weight:900; margin-bottom:15px; margin-top:20px; text-align:center;'>âš« YEARLY TREND ANALYSIS</h3>", unsafe_allow_html=True)
        # [ìˆ˜ì •] ìº¡ì…˜ ê°€ìš´ë° ì •ë ¬
        st.markdown("<div class='center-caption'>ì„ íƒí•œ ì—°ë„ì˜ ì›”ë³„ í‰ê·  í˜¼ì¡ë„ ì¶”ì´ì…ë‹ˆë‹¤.</div>", unsafe_allow_html=True)
        
        c1, c2 = st.columns([1, 6])
        with c1:
            st.markdown("**YEAR**")
            for y in [2023, 2024]:
                btn_type = "primary" if st.session_state['sel_year']==y else "secondary"
                if st.button(str(y), key=f"y_{y}", type=btn_type, use_container_width=True):
                    st.session_state['sel_year'] = y
                    st.rerun()
        with c2:
            y_df = spot_data[spot_data['ë‚ ì§œ'].dt.year == st.session_state['sel_year']]
            if not y_df.empty:
                monthly_stats = []
                for m in range(1, 13):
                    m_data = y_df[y_df['ë‚ ì§œ'].dt.month == m]
                    if not m_data.empty:
                        val, _ = get_smart_active_mean(m_data, spot_name)
                        monthly_stats.append({'month': m, 'val': val})
                
                if monthly_stats:
                    y_chart_df = pd.DataFrame(monthly_stats)
                    fig = px.line(y_chart_df, x='month', y='val', markers=True)
                    fig.update_traces(line_color='#000000', line_width=3)
                    fig.update_xaxes(tickmode='linear', tick0=1, dtick=1)
                    st.plotly_chart(style_chart(fig), use_container_width=True)
                    
                    cache_key = f"{spot_name}_{st.session_state['sel_year']}_trend"
                    if cache_key in st.session_state['analysis_results']['trend']:
                        content, color = st.session_state['analysis_results']['trend'][cache_key]
                        st.markdown(f"""<div class="ai-insight-box" style="border-left-color:{color};"><div class="ai-header" style="color:{color};">ğŸ“‰ DATA INSIGHT: {current_stage}</div>{content}</div>""", unsafe_allow_html=True)
                    else:
                        if st.button("ğŸ“„ AI ì‹¬ì¸µ ë¶„ì„ ë³´ê³ ì„œ ìƒì„± (Click)", key="btn_trend", use_container_width=True, type="primary"):
                            with st.spinner("ğŸ”„ AI ì‹¬ì¸µë¶„ì„ ì¤‘..."):
                                ranking = get_ranking_info(main_df, spot_name, st.session_state['sel_year'])
                                summary = y_chart_df.to_string(index=False)
                                res, color = generate_section_analysis("trend", spot_name, st.session_state['sel_year'], summary, current_stage, ranking)
                                st.session_state['analysis_results']['trend'][cache_key] = (res, color)
                                st.rerun()
                else: st.info("í•´ë‹¹ ì—°ë„ ë°ì´í„° ì—†ìŒ")
            else: st.info("í•´ë‹¹ ì—°ë„ ë°ì´í„° ì—†ìŒ")

        st.markdown("---")
        st.markdown("<h3 style='font-size:1.5rem; font-weight:900; margin-bottom:15px; text-align:center;'>âš« MONTHLY&HOURLY TREND ANALYSIS</h3>", unsafe_allow_html=True)
        # [ìˆ˜ì •] ìº¡ì…˜ ê°€ìš´ë° ì •ë ¬
        st.markdown("<div class='center-caption'>ì„ íƒí•œ ì›”ì˜ ì‹œê°„ëŒ€ë³„ í‰ê·  í˜¼ì¡ë„ ì¶”ì´ì…ë‹ˆë‹¤.</div>", unsafe_allow_html=True)
        
        st.markdown(f"**MONTH ({st.session_state['sel_year']})**")
        m_rows = [st.columns(6), st.columns(6)]
        for i in range(12):
            btn_type = "primary" if st.session_state['sel_month']==i+1 else "secondary"
            if m_rows[0 if i<6 else 1][i%6].button(f"{i+1}", key=f"m_{i+1}", type=btn_type, use_container_width=True):
                st.session_state['sel_month'] = i+1
                st.rerun()
        st.markdown(" ") 
        m_df = spot_data[(spot_data['ë‚ ì§œ'].dt.year == st.session_state['sel_year']) & (spot_data['ë‚ ì§œ'].dt.month == st.session_state['sel_month'])]
        if not m_df.empty:
            h_df = m_df.groupby(['ì‹œê°„ëŒ€_int', 'ì‹œê°„ëŒ€'])['ì‹¤ì§ˆ_ã¡ë‹¹_ë°©ë¬¸ê°ìˆ˜'].mean().reset_index().sort_values('ì‹œê°„ëŒ€_int')
            fig_h = px.area(h_df, x='ì‹œê°„ëŒ€', y='ì‹¤ì§ˆ_ã¡ë‹¹_ë°©ë¬¸ê°ìˆ˜')
            fig_h.update_traces(line_color='#666', fillcolor='rgba(0,0,0,0.1)')
            st.plotly_chart(style_chart(fig_h), use_container_width=True)
            
            key_h = f"hourly_{spot_name}_{st.session_state['sel_month']}"
            if key_h in st.session_state['analysis_results']['hourly']:
                content, color = st.session_state['analysis_results']['hourly'][key_h]
                st.markdown(f"""<div class="ai-insight-box" style="border-left-color:{color}; padding:15px; margin-top:10px;"><div class="ai-header" style="color:{color}; font-size:0.9rem;">â³ TIME ANALYSIS</div>{content}</div>""", unsafe_allow_html=True)
            else:
                if st.button("ğŸ“„ AI ì‹¬ì¸µ ë¶„ì„ ë³´ê³ ì„œ ìƒì„± (Click)", key="btn_hourly", use_container_width=True, type="primary"):
                    with st.spinner("ğŸ”„ AI ì‹¬ì¸µë¶„ì„ ì¤‘..."):
                        ranking = get_ranking_info(main_df, spot_name, st.session_state['sel_year'])
                        res, color = generate_section_analysis("hourly", spot_name, st.session_state['sel_year'], h_df.to_string(), current_stage, ranking)
                        st.session_state['analysis_results']['hourly'][key_h] = (res, color)
                        st.rerun()
        else: st.write("í•´ë‹¹ ì›” ë°ì´í„° ì—†ìŒ")

        st.markdown("---")
        st.markdown("<h3 style='font-size:1.5rem; font-weight:900; margin-bottom:15px; text-align:center;'>âš« 2025 FUTURE FORECAST</h3>", unsafe_allow_html=True)
        st.markdown("<div class='center-caption'>ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸(Prophet)ì´ ì˜ˆì¸¡í•œ 2025ë…„ ì›”ë³„ í˜¼ì¡ë„ ì¶”ì´ì…ë‹ˆë‹¤.</div>", unsafe_allow_html=True)
        
        if not forecast_df.empty:
            f_spot = forecast_df[forecast_df['ê´€ê´‘ì§€ëª…'] == spot_name]
            f_25 = f_spot[(f_spot['ds'] >= '2025-01-01') & (f_spot['ds'] <= '2025-12-31')]
            if not f_25.empty:
                mean_val = f_25['yhat'].mean()
                active_pred_val = f_25[f_25['yhat'] >= mean_val]['yhat'].mean()
                pred_stage = classify_density(active_pred_val)
                fig_f = px.line(f_25, x='ds', y='yhat')
                fig_f.update_traces(line_color='#000000', line_dash='dot')
                st.plotly_chart(style_chart(fig_f), use_container_width=True)
                key_f = f"forecast_{spot_name}"
                if key_f in st.session_state['analysis_results']['forecast']:
                    content, color = st.session_state['analysis_results']['forecast'][key_f]
                    st.markdown(f"""<div class="ai-insight-box" style="border-left-color:{color}; padding:15px; margin-top:10px;"><div class="ai-header" style="color:{color}; font-size:0.9rem;">ğŸ“ˆ PREDICTIVE ANALYTICS</div>{content}</div>""", unsafe_allow_html=True)
                else:
                    if st.button("ğŸ“„ AI ì‹¬ì¸µ ë¶„ì„ ë³´ê³ ì„œ ìƒì„± (Click)", key="btn_forecast", use_container_width=True, type="primary"):
                        with st.spinner("ğŸ”„ AI ì‹¬ì¸µë¶„ì„ ì¤‘..."):
                            res, color = generate_section_analysis("forecast", spot_name, 2025, f_25.head().to_string(), pred_stage)
                            st.session_state['analysis_results']['forecast'][key_f] = (res, color)
                            st.rerun()
        else: st.write("ì˜ˆì¸¡ ë°ì´í„° ì—†ìŒ")
# TAB 2: ìœ ì‚¬ë„ ë¶„ì„
    with tab2:
        st.markdown(" ") 
        
        # [í•„ìˆ˜] AI ë¶„ì„ ê²°ê³¼ ì €ì¥ì„ ìœ„í•œ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        if 'analysis_results' not in st.session_state:
            st.session_state['analysis_results'] = {'sim_img': {}, 'sim_strat': {}, 'weighted': {}}
        # í•˜ìœ„ í‚¤ ì•ˆì „ ì¥ì¹˜
        if 'sim_img' not in st.session_state['analysis_results']: st.session_state['analysis_results']['sim_img'] = {}
        if 'sim_strat' not in st.session_state['analysis_results']: st.session_state['analysis_results']['sim_strat'] = {}
        if 'weighted' not in st.session_state['analysis_results']: st.session_state['analysis_results']['weighted'] = {}

        tab_list = ["ì´ë¯¸ì§€ ìœ ì‚¬ë„", "í…ìŠ¤íŠ¸ ìœ ì‚¬ë„", "ì¢…í•© ìœ ì‚¬ë„", "Cross-Category"]
        cols = st.columns(4)
        for i, t_name in enumerate(tab_list):
            btn_style = "primary" if st.session_state['sim_sub_tab'] == t_name else "secondary"
            if cols[i].button(t_name, key=f"sub_t_{i}", use_container_width=True, type=btn_style):
                st.session_state['sim_sub_tab'] = t_name
                st.rerun()
        
        st.markdown("---")
        current_sub = st.session_state['sim_sub_tab']
        # [ìˆ˜ì •] ì—°ë„ë³„ í•„í„° ì ìš©ëœ ë°°ì§€ ê³„ì‚°
        _, source_cong = get_active_time_stats(main_df, spot_name, 2024)

        if current_sub == "ì´ë¯¸ì§€ ìœ ì‚¬ë„":
            st.markdown(f"<h4 style='text-align:center;'>Visual Similarity Analysis</h4>", unsafe_allow_html=True)
            st.markdown("<div class='center-caption'>ë”¥ëŸ¬ë‹ìœ¼ë¡œ ë¶„ì„í•œ ì‹œê°ì  ìœ ì‚¬ë„ ìˆœìœ„ì…ë‹ˆë‹¤.</div>", unsafe_allow_html=True)
            
            df_img = load_data_smart(FILE_CONFIG["IMG_RANK_DATA"])
            row = df_img[df_img['ëŒ€ìƒ_ê´€ê´‘ì§€'] == spot_name] if not df_img.empty else pd.DataFrame()
            
            # [NEW] ì „ì²´ ë°ì´í„°ì˜ 1ìˆœìœ„ í‰ê·  ì ìˆ˜ ê³„ì‚° (ë¹„êµ ë¶„ì„ìš©)
            avg_top1_score = 0.0
            if not df_img.empty and '1ìˆœìœ„' in df_img.columns:
                try:
                    # 'ê´€ê´‘ì§€ëª…(0.8123)' í˜•íƒœì—ì„œ ì ìˆ˜ë§Œ ì¶”ì¶œí•˜ì—¬ í‰ê·  ê³„ì‚°
                    scores = []
                    for val in df_img['1ìˆœìœ„'].astype(str):
                        match = re.search(r'\(([\d.-]+)\)', val)
                        if match: scores.append(float(match.group(1)))
                    if scores: avg_top1_score = sum(scores) / len(scores)
                except: pass

            if not row.empty:
                visual_candidates = []
                for i in range(1, 9):
                    col = f"{i}ìˆœìœ„"
                    if col in row.columns:
                        val = str(row.iloc[0][col])
                        match = re.search(r'(.+)\(([\d.-]+)\)', val)
                        if match:
                            t_name = match.group(1).strip()
                            t_score = float(match.group(2))
                            _, t_cong = get_active_time_stats(main_df, t_name, 2024)
                            visual_candidates.append({'rank': i, 'name': t_name, 'score': t_score, 'congestion': t_cong})
                
                if visual_candidates:
                    top1 = visual_candidates[0]
                    
                    st.markdown(f"#### ğŸ¥‡ PRIMARY ALTERNATIVE (Rank 1)")
                    
                    # [ë ˆì´ì•„ì›ƒ] ì¢Œì¸¡: ì´ë¯¸ì§€/ì •ë³´(1), ìš°ì¸¡: AI ë¶„ì„(1.2)
                    c1, c2 = st.columns([1, 1.2])
                    
                    # --- LEFT COLUMN: Image & Basic Info ---
                    with c1:
                        st.markdown(f"<div style='font-size:1.8rem; font-weight:800; line-height:1.2; margin-bottom:5px;'>{top1['name']}</div>", unsafe_allow_html=True)
                        cong_cls = "cong-bad" if top1['congestion'] in ['í˜¼ì¡', 'ë§¤ìš°í˜¼ì¡'] else ("cong-norm" if top1['congestion'] == 'ë³´í†µ' else "cong-good")
                        
                        # ì ìˆ˜ì™€ í˜¼ì¡ë„ í‘œì‹œ
                        st.markdown(f"""
                        <div style="margin-bottom:10px;">
                            <span class='congestion-badge {cong_cls}'>{top1['congestion']}</span>
                            <span style='font-family:monospace; font-weight:bold; color:#333; margin-left:5px;'>Sim: {top1['score']:.4f}</span>
                        </div>
                        """, unsafe_allow_html=True)
                        
                        img_path = os.path.join(BASE_DIR,"images", f"{top1['name']}.jpg")
                        if os.path.exists(img_path): st.image(img_path, use_container_width=True)
                        else: st.markdown("<div style='background:#F4F4F5; height:200px; border-radius:8px;'></div>", unsafe_allow_html=True)

                    # --- RIGHT COLUMN: AI Auto Insight (ìë™ ì‹¤í–‰ / ë°ì´í„° ì¤‘ì‹¬) ---
                    with c2:
                        auto_key = f"{spot_name}_vis_auto_analysis"
                        
                        # [í•µì‹¬ ìˆ˜ì •] ì„¸ì…˜ì— ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ë²„íŠ¼ í´ë¦­ ì—†ì´ ìë™ ì‹¤í–‰
                        if auto_key not in st.session_state['analysis_results']['sim_img']:
                            with st.spinner(f"ğŸ“Š {top1['name']} ë°ì´í„° ë¶„ì„ ì¤‘..."):
                                try:
                                    sim_diff = top1['score'] - avg_top1_score
                                    
                                    # [ìˆ˜ì •] 'name' í‚¤ ì¶”ê°€ (ì˜¤ë¥˜ í•´ê²°) ë° ë°ì´í„° ì¤‘ì‹¬ ì •ë³´ êµ¬ì„±
                                    data_info = {
                                        'name': spot_name,
                                        'target_name': top1['name'],
                                        'current_score': f"{top1['score']:.4f}",
                                        'average_benchmark': f"{avg_top1_score:.4f}", 
                                        'score_deviation': f"{sim_diff:+.4f}",
                                        'congestion_status': top1['congestion']
                                    }
                                    
                                    # anal_typeì„ 'ì´ë¯¸ì§€_ë°ì´í„°ë¶„ì„'ìœ¼ë¡œ ì „ë‹¬
                                    res = generate_strategic_analysis(data_info, [], anal_type="ì´ë¯¸ì§€_ë°ì´í„°ë¶„ì„")
                                    st.session_state['analysis_results']['sim_img'][auto_key] = res
                                except Exception as e:
                                    st.session_state['analysis_results']['sim_img'][auto_key] = f"ë¶„ì„ ì˜¤ë¥˜: {str(e)}"
                        
                        # ê²°ê³¼ í‘œì‹œ
                        if auto_key in st.session_state['analysis_results']['sim_img']:
                            st.markdown(f"""
                            <div class="ai-insight-box" style="height:100%; min-height:300px;">
                                <div class="ai-header">ğŸ“‰ DATA ANALYSIS</div>
                                {st.session_state['analysis_results']['sim_img'][auto_key]}
                            </div>""", unsafe_allow_html=True)

                    st.markdown("---")
                    
                    # 2, 3ìˆœìœ„ (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
                    r2_cols = st.columns(2)
                    for idx, cand in enumerate(visual_candidates[1:3]): 
                        cong_cls = "cong-bad" if cand['congestion'] in ['í˜¼ì¡', 'ë§¤ìš°í˜¼ì¡'] else ("cong-norm" if cand['congestion'] == 'ë³´í†µ' else "cong-good")
                        medal = "ğŸ¥ˆ" if cand['rank'] == 2 else "ğŸ¥‰"
                        label = "SECONDARY ALTERNATIVE" if cand['rank'] == 2 else "THIRD ALTERNATIVE"
                        
                        with r2_cols[idx]:
                            st.markdown(f"<div style='font-weight:700; margin-bottom:5px; font-size:1.8rem;'>{medal} {label} (Rank {cand['rank']})</div>", unsafe_allow_html=True)
                            i_path = os.path.join(BASE_DIR,"images", f"{cand['name']}.jpg")
                            if os.path.exists(i_path): st.image(i_path, use_container_width=True)
                            else: st.markdown("<div style='background:#EEE; height:150px; display:flex; align-items:center; justify-content:center; color:#999;'>NO IMAGE</div>", unsafe_allow_html=True)
                            st.markdown(f"<div style='font-weight:800; font-size:1.1rem;'>{cand['name']}</div>", unsafe_allow_html=True)
                            st.markdown(f"<span class='congestion-badge {cong_cls}'>{cand['congestion']}</span>", unsafe_allow_html=True)
                    
                    if len(visual_candidates) > 3:
                        st.markdown("#### OTHER CANDIDATES")
                        cols = st.columns(len(visual_candidates[3:]))
                        for idx, cand in enumerate(visual_candidates[3:]):
                            cong_cls = "cong-bad" if cand['congestion'] in ['í˜¼ì¡', 'ë§¤ìš°í˜¼ì¡'] else ("cong-norm" if cand['congestion'] == 'ë³´í†µ' else "cong-good")
                            with cols[idx]:
                                st.markdown(f"""<div class="rank-card-mini"><div style="font-size:0.7rem; color:#666;">RANK {cand['rank']}</div><div style="font-weight:700; font-size:0.85rem; margin:5px 0;">{cand['name']}</div><span class="congestion-badge {cong_cls}" style="font-size:0.6rem;">{cand['congestion']}</span></div>""", unsafe_allow_html=True)
                    
                    # [NEW] í•˜ë‹¨ ì¢…í•© AI ì‹¬ì¸µ ë¶„ì„ ë²„íŠ¼
                    st.markdown("---")
                    
                    total_key = f"{spot_name}_vis_total_report"
                    
                    if total_key in st.session_state['analysis_results']['sim_img']:
                        st.markdown(f"""<div class="ai-insight-box"><div class="ai-header">ğŸ§  VISUAL DEEP DIVE</div>{st.session_state['analysis_results']['sim_img'][total_key]}</div>""", unsafe_allow_html=True)

                    if st.button("ğŸ“„ AI ì‹¬ì¸µ ë¶„ì„ ë³´ê³ ì„œ ìƒì„± (Click)", key="btn_sim_img_total", use_container_width=True, type="primary"):
                        with st.spinner("ğŸ”„ ì‹œê° ë°ì´í„° ì¢…í•© ë¶„ì„ ì¤‘..."):
                            try:
                                summary_info = {
                                    'name': spot_name,
                                    'avg_score': avg_top1_score,
                                    'candidate_count': len(visual_candidates)
                                }
                                # ì „ì²´ í›„ë³´êµ°(visual_candidates)ì„ ë„˜ê²¨ì„œ ì¢…í•© ë¶„ì„
                                res = generate_strategic_analysis(summary_info, visual_candidates, anal_type="ì´ë¯¸ì§€_ì¢…í•©ë¶„ì„")
                                st.session_state['analysis_results']['sim_img'][total_key] = res
                                st.rerun()
                            except Exception as e:
                                st.error(f"Error: {str(e)}")

                else: st.info("ìœ ì‚¬ë„ ë°ì´í„° ì—†ìŒ")
            else: st.warning("ì´ë¯¸ì§€ ë¶„ì„ ë°ì´í„° ì—†ìŒ")

        elif current_sub == "í…ìŠ¤íŠ¸ ìœ ì‚¬ë„":
            st.markdown(f"<h4 style='text-align:center;'>Contextual Similarity Analysis</h4>", unsafe_allow_html=True)
            st.markdown("<div class='center-caption'>ë”¥ëŸ¬ë‹ìœ¼ë¡œ ë¶„ì„í•œ ë¦¬ë·° ìœ ì‚¬ë„ ìˆœìœ„ì…ë‹ˆë‹¤.</div>", unsafe_allow_html=True)
            
            nouns, adjs = get_spot_keywords(spot_name)
            if nouns or adjs:
                st.markdown(f"""<div class="keyword-box"><div class="keyword-header">IDENTITY OF {spot_name}</div><div style="margin-bottom:8px;"><span style="font-size:0.8rem; font-weight:700; margin-right:10px;">VIBE (ê°ì„±):</span>{' '.join([f"<span class='meta-tag tag-common'>#{k}</span>" for k in adjs[:5]])}</div><div><span style="font-size:0.8rem; font-weight:700; margin-right:10px;">FEATURE (ì‹œì„¤):</span>{' '.join([f"<span class='meta-tag tag-common'>#{k}</span>" for k in nouns[:5]])}</div></div>""", unsafe_allow_html=True)
            else: st.info("í‚¤ì›Œë“œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            df_rev = load_data_smart(FILE_CONFIG["REVIEW_SIM_DATA"])
            if not df_rev.empty:
                if 'ê´€ê´‘ì§€ëª…' in df_rev.columns: df_rev['ê´€ê´‘ì§€ëª…'] = df_rev['ê´€ê´‘ì§€ëª…'].ffill()
                targets = df_rev[df_rev['ê´€ê´‘ì§€ëª…'] == spot_name].head(5)
                if not targets.empty:
                    text_candidates = []
                    df_emo = load_data_smart(FILE_CONFIG["SENTIMENT_DATA"])
                    df_key = load_data_smart(FILE_CONFIG["FEATURE_DATA"])
                    for idx, row in enumerate(targets.iterrows(), 1):
                        _, data = row
                        target = data['ë¦¬ë·° ìœ ì‚¬ ê´€ê´‘ì§€']
                        score = data['ë¦¬ë·°ìœ ì‚¬ë„']
                        _, t_cong = get_active_time_stats(main_df, target, 2024)
                        common_vibe, unique_s_vibe, unique_t_vibe = [], [], []
                        common_feat, unique_s_feat, unique_t_feat = [], [], []
                        if not df_emo.empty:
                            e = df_emo[(df_emo['ê¸°ì¤€_ê´€ê´‘ì§€']==spot_name) & (df_emo['ë¹„êµ_ëŒ€ìƒ']==target)]
                            if not e.empty:
                                try: common_vibe = [k.strip() for k in str(e.iloc[0]['ê³µí†µ_í‚¤ì›Œë“œ']).split(',') if k.strip()][:3]
                                except: pass
                                try: unique_s_vibe = [k.strip() for k in str(e.iloc[0]['ê¸°ì¤€ì§€_ê³ ìœ _í‚¤ì›Œë“œ']).split(',') if k.strip()][:3]
                                except: pass
                                try: unique_t_vibe = [k.strip() for k in str(e.iloc[0]['ë¹„êµì§€_ê³ ìœ _í‚¤ì›Œë“œ']).split(',') if k.strip()][:3]
                                except: pass
                        if not df_key.empty:
                            k = df_key[(df_key['ê¸°ì¤€_ê´€ê´‘ì§€']==spot_name) & (df_key['ë¹„êµ_ëŒ€ìƒ']==target)]
                            if not k.empty:
                                try: common_feat = [k.strip() for k in str(k.iloc[0]['ì—£ì§€_ê³µí†µ_í‚¤ì›Œë“œ']).split(',') if k.strip()][:3]
                                except: pass
                                try: unique_s_feat = [k.strip() for k in str(k.iloc[0]['ê¸°ì¤€ì§€_ê³ ìœ ']).split(',') if k.strip()][:3]
                                except: pass
                                try: unique_t_feat = [k.strip() for k in str(k.iloc[0]['ë¹„êµì§€_ê³ ìœ ']).split(',') if k.strip()][:3]
                                except: pass
                        text_candidates.append({'rank': idx, 'name': target, 'score': score, 'congestion': t_cong, 'vibe_com': common_vibe, 'vibe_uniq_s': unique_s_vibe, 'vibe_uniq_t': unique_t_vibe, 'feat_com': common_feat, 'feat_uniq_s': unique_s_feat, 'feat_uniq_t': unique_t_feat})
                    def make_tags(tags, cls):
                        if not tags: return "<span style='color:#ccc; font-size:0.8rem;'>-</span>"
                        return ' '.join([f"<span class='meta-tag {cls}'>#{t}</span>" for t in tags])
                    for item in text_candidates:
                        cong_cls = "cong-bad" if item['congestion'] in ['í˜¼ì¡', 'ë§¤ìš°í˜¼ì¡'] else ("cong-norm" if item['congestion'] == 'ë³´í†µ' else "cong-good")
                        st.markdown(f"""<div class="sim-card"><div class="sim-header-row" style="display:flex; justify-content:space-between;"><div><span class="sim-rank-badge">RANK {item['rank']}</span><span class="congestion-badge {cong_cls}">{item['congestion']}</span></div><span class="sim-score">Sim: {item['score']:.4f}</span></div><div class="sim-title" style="margin-bottom:15px; margin-top:10px;">{item['name']}</div><div class="keyword-grid"><div><div class="keyword-col-header">COMMON (ê³µí†µ)</div>{make_tags(item['vibe_com'], 'tag-common')}<br>{make_tags(item['feat_com'], 'tag-common')}</div><div><div class="keyword-col-header">ONLY {spot_name}</div>{make_tags(item['vibe_uniq_s'], 'tag-unique-source')}<br>{make_tags(item['feat_uniq_s'], 'tag-unique-source')}</div><div><div class="keyword-col-header">ONLY {item['name']}</div>{make_tags(item['vibe_uniq_t'], 'tag-unique-target')}<br>{make_tags(item['feat_uniq_t'], 'tag-unique-target')}</div></div></div>""", unsafe_allow_html=True)
                    
                    st.markdown("---")
                    # [ìˆ˜ì •] í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ AI ì‘ë™ ë³´ì¥
                    if spot_name in st.session_state['analysis_results']['sim_strat']:
                        st.markdown(f"""<div class="ai-insight-box"><div class="ai-header">ğŸ§  CONTEXT DATA INSIGHT</div>{st.session_state['analysis_results']['sim_strat'][spot_name]}</div>""", unsafe_allow_html=True)
                    
                    if st.button("ğŸ“„ AI ì‹¬ì¸µ ë¶„ì„ ë³´ê³ ì„œ ìƒì„± (Click)", key="btn_sim_strat", use_container_width=True, type="primary"):
                        with st.spinner("ğŸ”„ AI ì‹¬ì¸µë¶„ì„ ì¤‘..."):
                            try:
                                source_info = {'name': spot_name, 'congestion': source_cong}
                                res = generate_strategic_analysis(source_info, text_candidates, anal_type="ë¦¬ë·°(Context)")
                                st.session_state['analysis_results']['sim_strat'][spot_name] = res
                                st.rerun()
                            except Exception as e:
                                st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                else: st.info("ìœ ì‚¬ë„ ë°ì´í„° ì—†ìŒ")
            else: st.warning("íŒŒì¼ ì—†ìŒ")

        # ì¢…í•© ìœ ì‚¬ë„ ë° Cross-CategoryëŠ” ê¸°ì¡´ ë¡œì§ ìœ ì§€ (ì•ˆì „ì¥ì¹˜ë§Œ ì¶”ê°€ë¨)
        elif current_sub == "ì¢…í•© ìœ ì‚¬ë„":
            st.markdown(f"<h4 style='text-align:center;'>Weighted Integrated Similarity</h4>", unsafe_allow_html=True)
            st.markdown("<div class='center-caption'>3ê°€ì§€ ì†ì„±(ì‹œê°, ê°ì„±, íŠ¹ì„±)ì— ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ì—¬ ìµœì ì˜ ëŒ€ì²´ì§€ë¥¼ ë„ì¶œí•©ë‹ˆë‹¤.</div>", unsafe_allow_html=True)
            
            st.info("ì´ë¯¸ì§€(Visual), ê°ì„±(Sentiment), íŠ¹ì„±(Feature) ë°ì´í„°ë¥¼ ì‚¬ìš©ìê°€ ì„¤ì •í•œ ê°€ì¤‘ì¹˜ë¡œ ê²°í•©í•©ë‹ˆë‹¤.")
            c1, c2, c3 = st.columns(3)
            w_vis = c1.number_input("ğŸ“¸ Visual Weight (ì‹œê°)", min_value=0, max_value=100, value=50, step=10, key="w_v_num")
            w_sen = c2.number_input("ğŸ’¬ Sentiment Weight (ê°ì„±)", min_value=0, max_value=100, value=30, step=10, key="w_s_num")
            w_fea = c3.number_input("ğŸŸï¸ Feature Weight (íŠ¹ì„±)", min_value=0, max_value=100, value=20, step=10, key="w_f_num")
            st.markdown(" ")
            
            if st.button("ğŸ” ê²°ê³¼ ë¶„ì„ ë° ìˆœìœ„ ì‚°ì¶œ (Click)", type="primary", use_container_width=True):
                with st.spinner("ë°ì´í„° ë¶„ì„ ì¤‘..."):
                    total_w = w_vis + w_sen + w_fea
                    if total_w == 0: total_w = 1 
                    if not df_vis_scaled.empty:
                        curr_v = df_vis_scaled[df_vis_scaled['ê¸°ì¤€_ê´€ê´‘ì§€'] == spot_name].drop_duplicates('ë¹„êµ_ëŒ€ìƒ').set_index('ë¹„êµ_ëŒ€ìƒ')['VIS_SCALED']
                        curr_s = pd.Series()
                        if not df_sen_scaled.empty: curr_s = df_sen_scaled[df_sen_scaled['ê¸°ì¤€_ê´€ê´‘ì§€'] == spot_name].drop_duplicates('ë¹„êµ_ëŒ€ìƒ').set_index('ë¹„êµ_ëŒ€ìƒ')['SEN_SCALED']
                        curr_f = pd.Series()
                        if not df_fea_scaled.empty: curr_f = df_fea_scaled[df_fea_scaled['ê¸°ì¤€_ê´€ê´‘ì§€'] == spot_name].drop_duplicates('ë¹„êµ_ëŒ€ìƒ').set_index('ë¹„êµ_ëŒ€ìƒ')['FEA_SCALED']
                        merged = pd.concat([curr_v, curr_s, curr_f], axis=1).fillna(0)
                        merged.columns = ['VIS_SCALED', 'SEN_SCALED', 'FEA_SCALED'] 
                        merged['FINAL_SCORE'] = ((merged['VIS_SCALED'] * w_vis) + (merged['SEN_SCALED'] * w_sen) + (merged['FEA_SCALED'] * w_fea)) / total_w
                        st.session_state['weighted_result'] = merged[merged.index != spot_name].sort_values(by='FINAL_SCORE', ascending=False).head(5)
                    else: st.warning("ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            if st.session_state['weighted_result'] is not None:
                res_df = st.session_state['weighted_result']
                st.markdown("---")
                st.markdown(f"<h4 style='text-align:center;'>ğŸ† TOP 5 WEIGHTED RECOMMENDATIONS</h4>", unsafe_allow_html=True)
                for rank, (cand_name, row) in enumerate(res_df.iterrows(), 1):
                    _, c_cong = get_active_time_stats(main_df, cand_name, 2024)
                    c_cong_cls = "cong-bad" if c_cong in ['í˜¼ì¡', 'ë§¤ìš°í˜¼ì¡'] else ("cong-norm" if c_cong == 'ë³´í†µ' else "cong-good")
                    st.markdown(f"""<div class="sim-card" style="padding: 20px;"><div style="display:flex; justify-content:space-between; align-items:center;"><div><span class="sim-rank-badge" style="background:#0F172A;">#{rank}</span><span style="font-size:1.2rem; font-weight:800; margin-right:10px;">{cand_name}</span><span class="congestion-badge {c_cong_cls}">{c_cong}</span></div><div style="text-align:right;"><div style="font-size:1.3rem; font-weight:900; color:#0F172A;">{row['FINAL_SCORE']:.4f}</div><div style="font-size:0.75rem; color:#666;">WEIGHTED SCORE</div></div></div><div style="margin-top:15px; background:#F8FAFC; padding:10px; border-radius:8px; display:flex; gap:15px;"><div style="flex:1; text-align:center;"><div style="font-size:0.7rem; color:#64748B;">VISUAL ({w_vis}%)</div><div style="font-weight:700;">{row['VIS_SCALED']:.2f}</div></div><div style="flex:1; text-align:center; border-left:1px solid #E2E8F0;"><div style="font-size:0.7rem; color:#64748B;">SENTIMENT ({w_sen}%)</div><div style="font-weight:700;">{row['SEN_SCALED']:.2f}</div></div><div style="flex:1; text-align:center; border-left:1px solid #E2E8F0;"><div style="font-size:0.7rem; color:#64748B;">FEATURE ({w_fea}%)</div><div style="font-weight:700;">{row['FEA_SCALED']:.2f}</div></div></div></div>""", unsafe_allow_html=True)
                top_cand = res_df.iloc[0]
                cand_info = {'name': res_df.index[0], 'raw_v': top_cand['VIS_SCALED'], 'raw_s': top_cand['SEN_SCALED'], 'raw_f': top_cand['FEA_SCALED']}
                st.markdown("---")
                if spot_name in st.session_state['analysis_results']['weighted']:
                      st.markdown(f"""<div class="ai-insight-box"><div class="ai-header">âš–ï¸ WEIGHTED INSIGHT</div>{st.session_state['analysis_results']['weighted'][spot_name]}</div>""", unsafe_allow_html=True)
                if st.button("ğŸ“„ AI ê°€ì¤‘ì¹˜ ê²°ê³¼ ë¶„ì„ (Click)", key="btn_weighted_ai", type="primary", use_container_width=True):
                    with st.spinner("ê°€ì¤‘ì¹˜ ê¸°ë°˜ ë¶„ì„ ì¤‘..."):
                        res = generate_weighted_insight(spot_name, cand_info, [w_vis, w_sen, w_fea])
                        st.session_state['analysis_results']['weighted'][spot_name] = res
                        st.rerun()

        elif current_sub == "Cross-Category":
            st.markdown(f"<h4 style='text-align:center;'>Cross-Category Analysis (Genre-Breaking)</h4>", unsafe_allow_html=True)
            st.markdown("<div class='center-caption'>ë™ì¼ ì¹´í…Œê³ ë¦¬ì˜ í‰ê·  ìœ ì‚¬ë„ë³´ë‹¤ ë†’ì€ ì ìˆ˜ë¥¼ ê°€ì§„(3ê°€ì§€ ê¸°ì¤€ ì¤‘ 3ê°œ ëª¨ë‘ ì¶©ì¡±), 'ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬'ì˜ ê´€ê´‘ì§€ ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.</div>", unsafe_allow_html=True)
            
            with st.spinner("ë‹¤ì°¨ì› êµì°¨ ë¶„ì„ ì¤‘..."):
                if not df_vis_scaled.empty:
                    curr_v = df_vis_scaled[df_vis_scaled['ê¸°ì¤€_ê´€ê´‘ì§€'] == spot_name].drop_duplicates('ë¹„êµ_ëŒ€ìƒ').set_index('ë¹„êµ_ëŒ€ìƒ')['VIS_SCALED']
                    curr_s = pd.Series()
                    if not df_sen_scaled.empty: curr_s = df_sen_scaled[df_sen_scaled['ê¸°ì¤€_ê´€ê´‘ì§€'] == spot_name].drop_duplicates('ë¹„êµ_ëŒ€ìƒ').set_index('ë¹„êµ_ëŒ€ìƒ')['SEN_SCALED']
                    curr_f = pd.Series()
                    if not df_fea_scaled.empty: curr_f = df_fea_scaled[df_fea_scaled['ê¸°ì¤€_ê´€ê´‘ì§€'] == spot_name].drop_duplicates('ë¹„êµ_ëŒ€ìƒ').set_index('ë¹„êµ_ëŒ€ìƒ')['FEA_SCALED']
                    
                    merged = pd.concat([curr_v, curr_s, curr_f], axis=1).fillna(0)
                    merged.columns = ['VIS_SCALED', 'SEN_SCALED', 'FEA_SCALED']
                    merged['FINAL_SCORE'] = ((merged['VIS_SCALED'] * 50) + (merged['SEN_SCALED'] * 30) + (merged['FEA_SCALED'] * 20)) / 100
                    
                    source_cat = get_spot_category(spot_name)
                    merged['CATEGORY'] = merged.index.map(get_spot_category)
                    
                    same_cat_group = merged[merged['CATEGORY'] == source_cat]
                    
                    if not same_cat_group.empty:
                        avg_vis = same_cat_group[same_cat_group['VIS_SCALED'] > 0]['VIS_SCALED'].mean()
                        avg_sen = same_cat_group[same_cat_group['SEN_SCALED'] > 0]['SEN_SCALED'].mean()
                        avg_fea = same_cat_group[same_cat_group['FEA_SCALED'] > 0]['FEA_SCALED'].mean()
                        if np.isnan(avg_vis): avg_vis = 0
                        if np.isnan(avg_sen): avg_sen = 0
                        if np.isnan(avg_fea): avg_fea = 0
                    else:
                        avg_vis, avg_sen, avg_fea = 0, 0, 0
                    
                    def check_all_pass(row):
                        mult = 1.0 
                        return (row['VIS_SCALED'] > avg_vis * mult) and \
                               (row['SEN_SCALED'] > avg_sen * mult) and \
                               (row['FEA_SCALED'] > avg_fea * mult)

                    candidates = merged[
                        (merged.index != spot_name) & 
                        (merged['CATEGORY'] != source_cat) & 
                        (merged['CATEGORY'] != 'ê¸°íƒ€')
                    ]
                    
                    filtered = candidates[candidates.apply(check_all_pass, axis=1)]
                    
                    st.session_state['cross_result'] = filtered.sort_values(by='FINAL_SCORE', ascending=False)
                    st.session_state['source_cat'] = source_cat
                    st.session_state['debug_avg'] = (avg_vis, avg_sen, avg_fea)
                else: st.warning("ë°ì´í„° ë¶€ì¡±")

            if st.session_state['cross_result'] is not None:
                res_df = st.session_state['cross_result']
                src_cat = st.session_state.get('source_cat', 'UNKNOWN')
                avgs = st.session_state.get('debug_avg', (0,0,0))
                mult = 1.0
                
                st.markdown(f"""
                <div style="padding:15px; background:#f8fafc; border-radius:8px; border:1px solid #e2e8f0; margin-bottom:20px;">
                    <div style="font-weight:700; color:#0f172a; margin-bottom:5px;">ğŸ“Š ANALYSIS CONTEXT</div>
                    <div style="font-size:0.85rem; color:#475569;">
                        í˜„ì¬ ì¹´í…Œê³ ë¦¬: <b>{src_cat}</b><br>
                        í†µê³¼ ê¸°ì¤€: <b>3ê°œ ì§€í‘œ ëª¨ë‘ ì¹´í…Œê³ ë¦¬ í‰ê·  ì´ìƒ (All Pass)</b><br>
                        <hr style="margin:8px 0; border-color:#e2e8f0;">
                        <b>[ì¹´í…Œê³ ë¦¬ í‰ê·  ì ìˆ˜]</b><br>
                        ğŸ“¸ ì‹œê°: {avgs[0]:.3f} / ğŸ’¬ ê°ì„±: {avgs[1]:.3f} / ğŸŸï¸ íŠ¹ì„±: {avgs[2]:.3f}
                    </div>
                </div>
                """, unsafe_allow_html=True)
                
                st.markdown("---")
                if not res_df.empty:
                    st.success(f"âœ… ì´ {len(res_df)}ê³³ì˜ ê²€ì¦ëœ ëŒ€ì²´ì§€ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    for rank, (cand_name, row) in enumerate(res_df.iterrows(), 1):
                        _, c_cong = get_active_time_stats(main_df, cand_name, 2024)
                        c_cong_cls = "cong-bad" if c_cong in ['í˜¼ì¡', 'ë§¤ìš°í˜¼ì¡'] else ("cong-norm" if c_cong == 'ë³´í†µ' else "cong-good")
                        tgt_cat = row['CATEGORY']
                        
                        v_pass = "âœ… Pass" if row['VIS_SCALED'] > avgs[0]*mult else "âŒ"
                        s_pass = "âœ… Pass" if row['SEN_SCALED'] > avgs[1]*mult else "âŒ"
                        f_pass = "âœ… Pass" if row['FEA_SCALED'] > avgs[2]*mult else "âŒ"
                        
                        st.markdown(f"""
                        <div class="sim-card" style="border-left: 5px solid #0369A1; background:#F0F9FF; margin-bottom:15px;">
                            <div style="display:flex; justify-content:space-between; align-items:center;">
                                <div>
                                    <span style="font-size:0.8rem; background:#FFF; padding:2px 8px; border:1px solid #DDD; border-radius:4px; font-weight:700; color:#333; margin-right:5px;">{tgt_cat}</span>
                                    <span style="font-size:1.3rem; font-weight:800;">{cand_name}</span>
                                </div>
                                <div style="text-align:right;">
                                    <div style="font-size:1.2rem; font-weight:900; color:#0F172A;">{row['FINAL_SCORE']:.2f}</div>
                                    <span class="congestion-badge {c_cong_cls}">{c_cong}</span>
                                </div>
                            </div>
                            <div style="margin-top:10px; font-size:0.8rem; color:#555; background:#fff; padding:10px; border-radius:6px; border:1px solid #e5e7eb;">
                                <strong>ğŸ“Š ìƒì„¸ ì§€í‘œ (í‰ê·  ëŒ€ë¹„)</strong><br>
                                ğŸ“¸ ì‹œê°: <b>{row['VIS_SCALED']:.3f}</b> {v_pass} <span style="color:#999;">(Avg: {avgs[0]:.3f})</span><br>
                                ğŸ’¬ ê°ì„±: <b>{row['SEN_SCALED']:.3f}</b> {s_pass} <span style="color:#999;">(Avg: {avgs[1]:.3f})</span><br>
                                ğŸŸï¸ íŠ¹ì„±: <b>{row['FEA_SCALED']:.3f}</b> {f_pass} <span style="color:#999;">(Avg: {avgs[2]:.3f})</span>
                            </div>
                        </div>""", unsafe_allow_html=True)
                else:
                    st.warning(f"ì¡°ê±´ì„ ì¶©ì¡±í•˜ëŠ” cross-category ëŒ€ì²´ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")