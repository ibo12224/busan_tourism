{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb178838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\dell5371\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (5.2.2)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\dell5371\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.36.0)\n",
      "Collecting huggingface_hub\n",
      "  Downloading huggingface_hub-1.3.7-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in c:\\users\\dell5371\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (4.57.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\dell5371\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (2.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\dell5371\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (2.2.6)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\dell5371\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (1.7.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\dell5371\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\dell5371\\appdata\\roaming\\python\\python310\\site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dell5371\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\dell5371\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (3.20.0)\n",
      "  Downloading huggingface_hub-0.36.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dell5371\\appdata\\roaming\\python\\python310\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dell5371\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\dell5371\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in c:\\users\\dell5371\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\dell5371\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\dell5371\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dell5371\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface_hub) (2025.12.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\dell5371\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\dell5371\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dell5371\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dell5371\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell5371\\appdata\\roaming\\python\\python310\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dell5371\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\dell5371\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers<6.0.0,>=4.41.0->sentence-transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell5371\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers<6.0.0,>=4.41.0->sentence-transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell5371\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers<6.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell5371\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.10.5)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\dell5371\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\dell5371\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Downloading huggingface_hub-0.36.1-py3-none-any.whl (566 kB)\n",
      "   ---------------------------------------- 0.0/566.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 566.3/566.3 kB 20.3 MB/s  0:00:00\n",
      "Installing collected packages: huggingface_hub\n",
      "  Attempting uninstall: huggingface_hub\n",
      "    Found existing installation: huggingface-hub 0.36.0\n",
      "    Uninstalling huggingface-hub-0.36.0:\n",
      "      Successfully uninstalled huggingface-hub-0.36.0\n",
      "Successfully installed huggingface_hub-0.36.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install -U sentence-transformers huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9871880d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jhgan/ko-sroberta-multitask] 부산 관광지 감성/맥락 분석 시작... (장치: cpu)\n",
      "  - [임베딩 완료] 남구_부산박물관\n",
      "  - [임베딩 완료] 남구_용호만부두\n",
      "  - [임베딩 완료] 남구_부산항대교\n",
      "  - [임베딩 완료] 남구_오륙도\n",
      "  - [임베딩 완료] 남구_이기대도시자연공원\n",
      "  - [임베딩 완료] 남구_UN공원\n",
      "  - [임베딩 완료] 해운대구_벡스코\n",
      "  - [임베딩 완료] 해운대구_더베이101\n",
      "  - [임베딩 완료] 해운대구_해운대블루라인파크\n",
      "  - [임베딩 완료] 해운대구_해운대해수욕장\n",
      "  - [임베딩 완료] 해운대구_송정해수욕장\n",
      "  - [임베딩 완료] 해운대구_누리마루\n",
      "  - [임베딩 완료] 해운대구_영화의전당\n",
      "  - [임베딩 완료] 해운대구_장산\n",
      "  - [임베딩 완료] 북구_화명생태공원\n",
      "  - [임베딩 완료] 북구_문화빙상센터\n",
      "  - [임베딩 완료] 북구_구포시장\n",
      "  - [임베딩 완료] 북구_부산어촌민속관\n",
      "  - [임베딩 완료] 부산진구_전포카페거리\n",
      "  - [임베딩 완료] 부산진구_황령산\n",
      "  - [임베딩 완료] 부산진구_송상현광장\n",
      "  - [임베딩 완료] 부산진구_호천마을\n",
      "  - [임베딩 완료] 부산진구_부전마켓타운\n",
      "  - [임베딩 완료] 부산진구_성지곡수원지\n",
      "  - [임베딩 완료] 동래구_금강공원\n",
      "  - [임베딩 완료] 동래구_동래온천\n",
      "  - [임베딩 완료] 동래구_동래읍성\n",
      "  - [임베딩 완료] 중구_자갈치시장\n",
      "  - [임베딩 완료] 중구_용두산공원\n",
      "  - [임베딩 완료] 중구_보수동책방골목\n",
      "  - [임베딩 완료] 중구_국제시장\n",
      "  - [임베딩 완료] 중구_비프광장\n",
      "  - [임베딩 완료] 사하구_감천문화마을\n",
      "  - [임베딩 완료] 사하구_부네치아\n",
      "  - [임베딩 완료] 사하구_아미산전망대\n",
      "  - [임베딩 완료] 사하구_다대포해수욕장\n",
      "  - [임베딩 완료] 사하구_낙동강하구에코센터\n",
      "  - [임베딩 완료] 사하구_을숙도생태공원\n",
      "  - [임베딩 완료] 사하구_다대포낙조분수\n",
      "  - [임베딩 완료] 금정구_회동수원지\n",
      "  - [임베딩 완료] 금정구_서동미로시장\n",
      "  - [임베딩 완료] 금정구_금정산성\n",
      "  - [임베딩 완료] 금정구_범어사\n",
      "  - [임베딩 완료] 영도구_태종대\n",
      "  - [임베딩 완료] 영도구_절영해안산책로\n",
      "  - [임베딩 완료] 영도구_국립해양박물관\n",
      "  - [임베딩 완료] 영도구_흰여울문화마을\n",
      "  - [임베딩 완료] 영도구_깡깡이예술마을\n",
      "  - [임베딩 완료] 영도구_영도대교\n",
      "  - [임베딩 완료] 영도구_아미르공원\n",
      "  - [임베딩 완료] 사상구_삼락생태공원\n",
      "  - [임베딩 완료] 사상구_사상인디스테이션\n",
      "  - [임베딩 완료] 강서구_맥도생태공원\n",
      "  - [임베딩 완료] 강서구_대저생태공원\n",
      "  - [임베딩 완료] 강서구_강서체육공원\n",
      "  - [임베딩 완료] 동구_초량이바구길\n",
      "  - [임베딩 완료] 동구_상해거리\n",
      "  - [임베딩 완료] 기장군_안데르센마을\n",
      "  - [임베딩 완료] 기장군_부산프리미엄아울렛\n",
      "  - [임베딩 완료] 기장군_아홉산숲\n",
      "  - [임베딩 완료] 기장군_임랑해수욕장\n",
      "  - [임베딩 완료] 기장군_장안사\n",
      "  - [임베딩 완료] 기장군_야구등대\n",
      "  - [임베딩 완료] 기장군_일광해수욕장\n",
      "  - [임베딩 완료] 기장군_부산치유의숲\n",
      "  - [임베딩 완료] 서구_남항대교\n",
      "  - [임베딩 완료] 서구_구덕운동장\n",
      "  - [임베딩 완료] 서구_구덕야영장\n",
      "  - [임베딩 완료] 서구_송도용궁구름다리\n",
      "  - [임베딩 완료] 서구_송도해수욕장\n",
      "  - [임베딩 완료] 서구_석당박물관\n",
      "  - [임베딩 완료] 수영구_광안대교\n",
      "  - [임베딩 완료] 수영구_광안리SUPZONE\n",
      "\n",
      "변별력 강화를 위한 벡터 보정 및 유사도 계산 중...\n",
      "\n",
      "[최종 완료] 결과 파일: busan_sbert_final_recommend.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# 환경 설정 및 타임아웃 방지\n",
    "os.environ['HF_HUB_READ_TIMEOUT'] = '100'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# 1. 모델 로드 (한국어 문맥 파악에 최적화)\n",
    "model_name = 'jhgan/ko-sroberta-multitask'\n",
    "model = SentenceTransformer(model_name, device=device)\n",
    "\n",
    "root_path = r'G:\\내 드라이브\\빅데이터_부산\\텍스트(네이버 리뷰)' \n",
    "preprocessed_data = []\n",
    "\n",
    "def clean_text(text):\n",
    "    if pd.isna(text): return \"\"\n",
    "    text = str(text)\n",
    "    \n",
    "    # 1. 제거할 문구 리스트 (더 강력하게 보강)\n",
    "    noise_patterns = [\n",
    "        '소정의 원고료', '재배포 금지', '무단 전재', '내돈내산', '협찬받아', \n",
    "        '부산 여행', '부산 가볼만한곳', '부산 데이트', '부산 나들이', '추천합니다'\n",
    "    ]\n",
    "    \n",
    "    for p in noise_patterns:\n",
    "        text = text.replace(p, \"\")\n",
    "        \n",
    "    # 2. 의미 없는 공백 및 특수문자 정리\n",
    "    text = re.sub(r'[^가-힣0-9a-zA-Z\\s]', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "print(f\"[{model_name}] 부산 관광지 감성/맥락 분석 시작... (장치: {device})\")\n",
    "\n",
    "# 2. 데이터 순회 및 임베딩 생성\n",
    "for addr, dirs, files in os.walk(root_path):\n",
    "    for file_name in files:\n",
    "        if file_name.endswith(('.csv', '.xlsx')):\n",
    "            file_path = os.path.join(addr, file_name)\n",
    "            place_name = f\"{os.path.basename(addr)}_{os.path.splitext(file_name)[0]}\"\n",
    "            \n",
    "            try:\n",
    "                df = pd.read_csv(file_path) if file_name.endswith('.csv') else pd.read_excel(file_path)\n",
    "                \n",
    "                blog_texts = []\n",
    "                for _, row in df.iterrows():\n",
    "                    title = clean_text(row.get('제목', ''))\n",
    "                    content = clean_text(row.get('본문', ''))\n",
    "                    \n",
    "                    # [전략] 제목 5번 반복으로 가중치 부여 + 본문 800자 (맥락 파악용)\n",
    "                    combined_text = (f\"{title} \" * 2) + content[:1200]\n",
    "                    if len(combined_text) > 30: \n",
    "                        blog_texts.append(combined_text)\n",
    "\n",
    "                # 최소 5개 이상의 리뷰가 있어야 신뢰도 확보\n",
    "                if len(blog_texts) >= 5:\n",
    "                    with torch.no_grad():\n",
    "                        # 관광지별 '평균 벡터' 생성\n",
    "                        embeddings = model.encode(blog_texts, batch_size=32, convert_to_tensor=True)\n",
    "                        place_vector = torch.mean(embeddings, dim=0).cpu().numpy()\n",
    "                    \n",
    "                    preprocessed_data.append({'place_name': place_name, 'vector': place_vector})\n",
    "                    print(f\"  - [임베딩 완료] {place_name}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  - [오류] {place_name}: {e}\")\n",
    "\n",
    "# 3. 유사도 점수 변별력 강화 (Zero-Centering 후처리)\n",
    "print(\"\\n변별력 강화를 위한 벡터 보정 및 유사도 계산 중...\")\n",
    "\n",
    "names = [d['place_name'] for d in preprocessed_data]\n",
    "vectors = np.array([d['vector'] for d in preprocessed_data])\n",
    "\n",
    "# [핵심] 모든 벡터에서 전체 평균을 빼서 각 장소만의 특징을 극대화함 (점수 편중 해결)\n",
    "centroid = np.mean(vectors, axis=0)\n",
    "centered_vectors = vectors - centroid\n",
    "\n",
    "# 코사인 유사도 계산\n",
    "sim_matrix = util.cos_sim(centered_vectors, centered_vectors).numpy()\n",
    "\n",
    "# 4. 결과 저장 (가로 확장형)\n",
    "final_rows = []\n",
    "for i, base_name in enumerate(names):\n",
    "    scores = sim_matrix[i]\n",
    "    sorted_idx = np.argsort(scores)[::-1]\n",
    "    \n",
    "    row = {'기준_관광지': base_name}\n",
    "    rank = 1\n",
    "    for idx in sorted_idx:\n",
    "        target_name = names[idx]\n",
    "        if base_name != target_name:\n",
    "            # 점수가 더 넓게 퍼진 상태로 저장됨\n",
    "            row[f'유사_관광지_{rank}'] = f\"{target_name}({scores[idx]:.4f})\"\n",
    "            rank += 1\n",
    "            if rank > 10: break\n",
    "    final_rows.append(row)\n",
    "\n",
    "pd.DataFrame(final_rows).to_csv('busan_sbert_final_recommend.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"\\n[최종 완료] 결과 파일: busan_sbert_final_recommend.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c6bfc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[최종 완료] 결과 파일: busan_sbert_final_recommend.csv\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(final_rows).to_csv('busan_sbert_final_recommend.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"\\n[최종 완료] 결과 파일: busan_sbert_final_recommend.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e19f5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'감상분석 유사도' 매트릭스 생성 중...\n",
      "[추가 완료] 모든 관광지 간 유사도 표 저장 완료: 감상분석 유사도.csv\n"
     ]
    }
   ],
   "source": [
    "# 5. 모든 관광지 간의 유사도 매트릭스 저장 (정방 행렬 형태)\n",
    "print(\"\\n'감상분석 유사도' 매트릭스 생성 중...\")\n",
    "\n",
    "# 유사도 매트릭스를 데이터프레임으로 변환 (인덱스와 컬럼명을 관광지명으로 설정)\n",
    "df_similarity_matrix = pd.DataFrame(sim_matrix, index=names, columns=names)\n",
    "\n",
    "# 파일 저장\n",
    "output_filename = '감상분석 유사도.csv'\n",
    "df_similarity_matrix.to_csv(output_filename, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"[추가 완료] 모든 관광지 간 유사도 표 저장 완료: {output_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
